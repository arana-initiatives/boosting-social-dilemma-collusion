env_name: "CollusionDilemmaEnv"
num_agents: 2
hetero_prob: 0.5
eps_len: 10
framework: "torch" # framework specifier, choices=["tf", "tf2", "torch"]
as_test: True # actions: "store_true" or "store_false", script running as test or not
# stop_reward must be achieved within stop_timesteps AND stop_iters
stop_iters: 50 # number of iterations to train
stop_timesteps: 5000 # number of timesteps to train
# reward value accumulated over 100 episodes, 150/200 shows 75 % collusion rate
stop_reward: 200 # feasable reward choice 100 but not 200, reward at which we stop training
policy_choices: ["always_same", "beat_last"]
train_batch_size: 200
gamma: 0.9
metric_smoothing_eps_len: 100
